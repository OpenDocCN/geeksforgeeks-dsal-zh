# 程序员查看数组与链接列表

的方法

通常，数组被认为是一种数据结构，其大小在编译时是固定的，并且数组存储器是从“数据”部分（例如，全局数组）或“堆栈”部分（例如，本地数组）中分配的。
类似地，链表被认为是一种数据结构，其大小不固定，并且在需要时从堆部分（例如，使用malloc（）等）分配内存。 从这个意义上说，数组被视为静态数据结构（位于“数据”或“堆栈”部分），而链表被视为动态数据结构（位于“堆”部分）。 数组和链表的内存表示可以如下所示：

分别用1、2、3和4初始化的4个元素（整数类型）的数组。假设，这些元素分别分配给内存地址0x100、0x104、0x108和0x10C。

```
[(1)]       [(2)]      [(3)]      [(4)]
0x100       0x104      0x108      0x10C
```

一个具有4个节点的链表，其中每个节点都有整数作为数据，并且这些数据分别用1、2、3和4初始化。假设这些节点是通过malloc（）分配的，并且为其分配的内存为0x200、0x308、0x404和0x20B 分别。

```
[(1), 0x308]     [(2),0x404]      [(3),0x20B]       [(4),NULL]  
  0x200            0x308            0x404              0x20B  
```

任何对数组和链接列表了解甚少的人可能对以上解释都不感兴趣。 我的意思是，众所周知，数组元素是按顺序分配内存的，即连续内存，而链表的节点在内存中是不连续的。 尽管听起来很琐碎，但这是数组和链表之间最重要的区别。 应该注意的是，由于此连续内存与非连续内存的关系，数组和链接列表是不同的。 实际上，这种差异就是数组与链表的区别！ 在以下各节中，我们将尝试进一步探索这一想法。

由于数组的元素在内存中是连续的，因此我们可以使用索引（例如）随机访问任何元素。 intArr [3]将直接访问数组的第四个元素。 （对于新手，数组索引从0开始，这就是为什么第四个元素以3索引的原因）。 而且，由于用于阵列中连续元素的连续存储器，不需要在单独的元素中存储额外的信息，即，阵列中的元数据没有开销。 与此相反，链接列表节点在内存中不连续。 这意味着我们需要某种机制来遍历或访问链表节点。 为此，每个节点都存储下一个节点的位置，这形成了从一个节点到下一个节点的链接的基础。 因此，它称为“链接列表”。 尽管存储下一个节点的位置在链表中是开销，但这是必需的。 通常，我们看到链表节点声明如下：

```

struct llNode 
{ 
  int dataInt; 

  /* nextNode is the pointer to next node in linked list*/
  struct llNode * nextNode;     
};

```

因此，数组元素在内存中是连续的，因此不需要任何元数据。 并且链接列表节点在内存中不连续，因此需要下一个节点的位置形式的元数据。 除了这种差异之外，我们可以看到该数组可能有几个未使用的元素，因为已经分配了内存。 但是链接列表将仅具有必需的编号。 数据项。 以上有关数组和链表的所有信息已在几本教科书中以不同的方式提及。

What if we need to allocate array memory from Heap section (i.e. at run time) and linked list memory from Data/Stack section. First of all, is it possible? Before that, one might ask why would someone need to do this? Now, I hope that the remaining article would make you rethink about the idea of array vs. linked-list 🙂

现在考虑需要将某些数据存储在数组中的情况（因为数组由于连续的内存而具有随机访问的属性），但我们不知道先验的总大小。 一种可能性是在运行时从Heap分配此数组的内存。 例如，如下：

/ *在运行时，假设我们知道整数数组所需的大小（例如，用户输入的大小）。 说，数组大小存储在变量arrSize中。 从堆中分配此数组，如下所示* /

```

int * dynArr = (int *)malloc(sizeof(int)*arrSize); 

```

尽管此数组的内存是从堆中分配的，但仍可以通过索引机制（例如 dynArr [i]。 基本上，基于编程问题，我们结合了数组的一项好处（即元素的随机访问）和链表的一项好处（即将内存分配延迟到运行时并从Heap分配内存）。 拥有这种类型的动态数组的另一个优点是，这种在运行时从堆中分配数组的方法可以减小代码大小（当然，这取决于某些其他因素，例如程序格式等）。

现在考虑当我们需要将数据存储在链表中时的情况（因为链表中节点的数量将等于存储的实际数据项，即没有额外的空间，如数组），但是我们不允许从中获取此内存 为每个节点一次又一次地堆。 对于某些人来说，这可能是假设的情况，但在嵌入式系统中并不是很常见的要求。 基本上，在多个嵌入式程序中，由于多种原因，不允许通过malloc（）等分配内存。 一个明显的原因是性能，即通过malloc（）分配内存在时间复杂度上是昂贵的，因为大多数情况下要求嵌入式程序具有确定性。 另一个原因可能是特定于模块的内存管理，即嵌入式系统中的每个模块都有可能管理自己的内存。 简而言之，如果我们需要执行自己的内存管理，而不是依靠系统提供的malloc（）和free（）的API，我们可以选择使用数组模拟的链表。 我希望您有所了解，为什么我们可能需要使用数组来模拟链接列表。 现在，让我们首先看看如何做到这一点。 假设链表（即基础数组）中节点的类型声明如下：

```

struct sllNode 
{ 
  int dataInt; 

 /*Here, note that nextIndex stores the location of next node in 
  linked list*/
  int nextIndex;  
}; 

struct sllNode arrayLL[5];

```

如果我们初始化此链表（实际上是一个数组），则它在内存中的外观如下：

```
[(0),-1]    [(0),-1]    [(0),-1]   [(0),-1]   [(0),-1]
0x500        0x508       0x510      0x518      0x520
```

需要注意的重要一点是，链表的所有节点在内存中都是连续的（每个节点占用8个字节），每个节点的nextIndex设置为-1。 这样做（即-1）表示链表的每个节点到目前为止都是空的。 此链接列表由头索引0表示。

现在，如果此链表用数据部分4、3、2和1的四个元素连续更新，则在内存中将如下所示。 该链接列表可以视为0x500-> 0x508-> 0x510-> 0x518。

```
[(1),1]       [(2),2]      [(3),3]     [(4),-2]     [(0),-1]
 0x500         0x508        0x510       0x518        0x520
```

要注意的重要一点是最后一个节点（即第四个节点）的nextIndex设置为-2。 执行此操作（即-2）以表示链接列表的末尾。 而且，链表的头节点是索引0。如果我们从上述链表中删除第二个节点，则使用数组模拟链表的概念将变得更加有趣。 在这种情况下，链接列表在内存中将如下所示：

```
[(1),2]       [(0),-1]      [(3),3]     [(4),-2]     [(0),-1]
 0x500         0x508         0x510       0x518        0x520
```

结果链表为0x500-> 0x510-> 0x518。 在这里，应该注意的是，即使我们从链表中删除了第二个节点，该节点的内存仍然存在，因为基础数组仍然存在。 但是，第一个节点的nextIndex现在指向第三个节点（其索引为2）。

希望上面的示例能给我们一些想法，对于模拟的链表，我们需要编写类似于malloc（）和free（）的自己的API，这些API基本上将用于插入和删除节点。 现在，这就是所谓的自己的内存管理。 让我们看看如何以算法方式完成此操作。

有多种方法可以这样做。 如果我们采用使用数组创建链表的简单方法，则可以使用以下逻辑。 要插入节点，请遍历基础数组并找到nextIndex为-1的节点。 这意味着该节点为空。 将此节点用作新节点。 更新此新节点中的数据部分，并将此节点的nextIndex设置为链接列表的当前头节点（即头索引）。 最后，将该新节点的索引作为链表的头索引。 为了形象化它，让我们举一个例子。 假设链表如下，其中head索引为0，即链表为0x500-> 0x508-> 0x518-> 0x520

```
[(1),1]       [(2),3]      [(0),-1]     [(4),4]     [(5),-2]
 0x500         0x508        0x510        0x518       0x520
```

在插入带有数据8的新节点后，链接列表将如下所示，头索引为2。

```
[(1),1]       [(2),3]      [(8),0]     [(4),4]     [(5),-2]
 0x500         0x508        0x510       0x518       0x520
```

因此链接列表节点将位于地址0x510-> 0x500-> 0x508-> 0x518-> 0x520

要删除节点，我们需要将节点的nextIndex设置为-1，以便将该节点标记为空节点。 但是，在这样做之前，我们需要确保上一个节点的nextIndex正确更新为要删除的该节点的下一个节点的索引。 我们可以看到我们已经完成了自己的内存管理，可以从阵列内存中创建链接列表。 但是，这是在此链表中插入和删除节点的一​​种方法。 可以很容易地注意到，就时间复杂度而言，找到一个空节点并不是那么有效。 基本上，我们是线性搜索整个数组以找到一个空节点。

让我们看看是否可以进一步优化它。 基本上，我们可以在同一数组中维护一个空节点的链接列表。 在那种情况下，链表将由两个索引表示–一个索引将用于链表，该链表具有实际的数据值，即到目前为止已插入的节点，而其他索引则用于空节点的链表。 这样，每当需要在现有链表中插入一个新节点时，我们都可以快速找到一个空节点。 让我们举个例子：

```
[(4),2]    [(0),3]    [(5),5]    [(0),-1]   [(0),1]   [(9),-1]
 0x500      0x508      0x510      0x518      0x520      0x528
```

上面的链接列表由两个索引（0和5）表示，具有两个链接列表：一个用于实际值，另一个用于空节点。 具有实际值的链表的节点位于地址0x500-> 0x510-> 0x528，而具有空节点的链表的节点位于地址0x520-> 0x508-> 0x518。 可以看出，现在找到空节点（即编写类似于malloc（）的自己的API）应该相对更快，因为我们可以快速找到一个空闲节点。 在现实世界中的嵌入式程序中，模块仅使用malloc（）分配一次固定的内存块（通常称为内存池）。 然后，由该模块本身使用前面提到的技术来管理该内存池（基本上是一个数组）。 有时，有多个内存池，每个内存池具有不同的节点大小。 当然，自己的内存管理还有其他几个方面，但我们将其保留在这里。 但值得一提的是，有几种方法可以进一步改善插入（需要我们自己的内存分配）和删除（需要我们自己的内存释放）。

如果我们仔细看，会发现内存的堆部分基本上是一个大字节数组，由底层操作系统（OS）管理。 而且OS正在通过malloc（），free（）等为程序员提供这种内存管理服务。

本文的重要内容总结如下：

A）数组表示连续内存。 它可以存在于任何数据段，数据段或堆栈或堆中。
B）链接列表表示不连续的链接内存。 它可以存在于堆，数据或堆栈的任何内存部分中。
C）作为程序员，从内存的角度看待数据结构可以为我们提供更好的洞察力，帮助您选择特定的数据结构甚至设计新的数据结构。 例如，我们可以创建一个链接列表数组等。

如果发现任何不正确的地方，或者您想分享有关上述主题的更多信息，请发表评论

注意读者！ 现在不要停止学习。 通过 [**DSA自学课程**](https://practice.geeksforgeeks.org/courses/dsa-self-paced?utm_source=geeksforgeeks&utm_medium=article&utm_campaign=gfg_article_dsa_content_bottom) 以对学生方便的价格掌握所有重要的DSA概念，并为行业做好准备。